## Week 1: ML Intro
### Prerequisites
- Python
- Math
- pip, Anokomda, poetry
- Jupiter Notebook
- Docker (optional)

### EDA with pahdas
- sorting, indexing, grupping, sunmmary tables
- undestanding dataFrame transformation
- understanding and managing model parameters (temperature, top_p, max_tokens)

### Visual data analysis in Python 
- Univariante visualisation: categorical and binary features 
- multivariare visualization: quantitative vs. quantitative, quantitative vs. categorical,  categorical vs. categorical
- whole dataset visualizations

### Classification, Decision Trees and k Nearest Neighbors
 - theory and algorithms
 - maximum likelihood estimation 
 - regularization of linear regression
 - choosing Model Parameters and Cross-Validation

###  Linear Classification and Regression
-  theory and algorithms
 - maximum likelihood estimation 
 - regularization of linear regression
 - choosing Model Parameters and Cross-Validation

### Bagging and Random Forest
- theory and algorithms
- ensembles
- bootstrapping
- bagging

### Feature Engineering and Feature Selection
- feature extraction (texts, images, Geospatial data, Date and time, Time series, web, etc.)
- feature transformations (normalization and changing distribution, interactions, filling in the missing values)
- feature selection (statistical approaches, selection by modeling, grid search)

[course: https://mlcourse.ai/book/index.html]

[addidional curses: https://www.w3schools.com/python/pandas/default.asp
https://www.w3schools.com/datascience/default.asp
https://www.w3schools.com/statistics/index.php
https://www.w3schools.com/ai/default.asp]